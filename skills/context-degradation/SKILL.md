---
name: context-degradation
description: このスキルは、ユーザーが「コンテキストの問題を診断する」「lost-in-middleの問題を修正する」「エージェントの障害をデバッグする」「コンテキストポイズニングを理解する」と求めた場合、またはコンテキストの劣化、アテンションパターン、コンテキストの衝突、コンテキストの混乱、エージェントのパフォーマンス低下について言及する場合に使用します。コンテキスト障害の認識と緩和のためのパターンを提供します。
---

# コンテキスト劣化パターン

言語モデルは、コンテキストの長さが増加するにつれて予測可能な劣化パターンを示します。これらのパターンを理解することは、障害の診断とレジリエントなシステムの設計に不可欠です。コンテキストの劣化は二値的な状態ではなく、いくつかの異なる方法で現れるパフォーマンス劣化の連続体です。

## 有効化のタイミング

以下の場合にこのスキルを有効化してください：
- 長い会話中にエージェントのパフォーマンスが予期せず低下する場合
- エージェントが不正確または無関係な出力を生成するケースのデバッグ時
- 大規模なコンテキストを確実に処理する必要があるシステムの設計時
- プロダクションシステムのコンテキストエンジニアリングの選択を評価する時
- エージェント出力における「lost in middle」現象の調査時
- エージェントの動作におけるコンテキスト関連の障害を分析する時

## コアコンセプト

コンテキストの劣化は、いくつかの異なるパターンを通じて現れます。lost-in-middle現象は、コンテキストの中央にある情報が受けるアテンションが少なくなる原因となります。コンテキストポイズニングは、エラーが繰り返し参照されることで複合化する時に発生します。コンテキストディストラクションは、無関係な情報が関連コンテンツを圧倒する時に起こります。コンテキストコンフュージョンは、モデルがどのコンテキストが適用されるかを判断できない時に発生します。コンテキストクラッシュは、蓄積された情報が直接矛盾する時に発展します。

これらのパターンは予測可能であり、コンパクション、マスキング、パーティショニング、分離などのアーキテクチャパターンによって緩和できます。

## 詳細トピック

### Lost-in-Middle現象

最もよく文書化されている劣化パターンは「lost-in-middle」効果で、モデルがU字型のアテンション曲線を示します。コンテキストの先頭と末尾にある情報は確実にアテンションを受けますが、中間に埋もれた情報はリコール精度が劇的に低下します。

**実証的エビデンス**
研究によると、コンテキストの中間に配置された関連情報は、先頭または末尾にある同じ情報と比較して、リコール精度が10〜40%低下します。これはモデルの障害ではなく、アテンションメカニクスと学習データ分布の結果です。

モデルは内部状態を安定させるために、最初のトークン（多くの場合BOSトークン）に大量のアテンションを割り当てます。これにより、アテンションバジェットを吸収する「アテンションシンク」が作成されます。コンテキストが成長するにつれて、限られたバジェットはさらに薄く引き伸ばされ、中間のトークンは信頼性の高い検索に十分なアテンション重みを獲得できなくなります。

**実践的な影響**
アテンションパターンを念頭に置いてコンテキストの配置を設計します。重要な情報をコンテキストの先頭または末尾に配置します。情報が直接クエリされるのか、推論をサポートする必要があるのかを考慮してください—後者の場合、配置はそれほど重要ではありませんが、全体的なシグナル品質がより重要になります。

長いドキュメントや会話では、アテンションが優遇されるポジションに重要な情報を表面化させるサマリー構造を使用します。モデルが構造をナビゲートするのを助けるために、明示的なセクションヘッダーとトランジションを使用します。

### コンテキストポイズニング

コンテキストポイズニングは、ハルシネーション、エラー、または不正確な情報がコンテキストに入り、繰り返し参照されることで複合化する時に発生します。一度汚染されると、コンテキストは不正確な信念を強化するフィードバックループを作成します。

**ポイズニングの発生方法**
ポイズニングは通常、3つの経路を通じて入り込みます。第一に、ツール出力にエラーや予期しないフォーマットが含まれ、モデルがそれを正しい情報として受け入れる場合があります。第二に、検索されたドキュメントに不正確または古い情報が含まれ、モデルがそれを推論に組み込む場合があります。第三に、モデルが生成したサマリーや中間出力にハルシネーションが導入され、コンテキストに残り続ける場合があります。

複合効果は深刻です。エージェントの目標セクションが汚染されると、元に戻すのに多大な労力を要する戦略を展開します。後続の各判断が汚染されたコンテンツを参照し、不正確な仮定を強化します。

**検出と回復**
以前成功していたタスクでの出力品質の低下、エージェントが間違ったツールやパラメータを呼び出すツールの不整合、修正の試みにもかかわらず持続するハルシネーションなどの症状に注意してください。これらの症状が現れた場合、コンテキストポイズニングを疑ってください。

回復には、汚染されたコンテンツの除去または置換が必要です。ポイズニング発生前のポイントまでコンテキストを切り詰める、コンテキスト内でポイズニングを明示的に記載して再評価を求める、またはクリーンなコンテキストで再起動し検証済みの情報のみを保持することが含まれます。

### コンテキストディストラクション

コンテキストディストラクションは、コンテキストが長くなりすぎて、モデルが学習知識を犠牲にして提供された情報に過度に集中する時に発生します。モデルは関連性に関わらずコンテキスト内のすべてに注意を向け、これにより内部知識がより正確な場合でも提供された情報を使用するプレッシャーが生まれます。

**ディストラクター効果**
研究によると、コンテキスト内のたった1つの無関係なドキュメントでも、関連ドキュメントを含むタスクのパフォーマンスが低下します。複数のディストラクターは劣化を複合化します。効果はノイズの絶対量ではなく、アテンション配分に関するものです—無関係な情報が限られたアテンションバジェットをめぐって関連情報と競合します。

モデルには、無関係なコンテキストを「スキップ」するメカニズムがありません。提供されたすべてに注意を向けなければならず、この義務は無関係な情報が明らかに有用でない場合でもディストラクションを引き起こします。

**緩和戦略**
コンテキストに入るものの慎重なキュレーションによってディストラクションを緩和します。検索されたドキュメントをロードする前に関連性フィルタリングを適用します。名前空間と整理を使用して、無関係なセクションを構造的に無視しやすくします。情報が本当にコンテキスト内にある必要があるのか、代わりにツールコールを通じてアクセスできるのかを検討します。

### コンテキストコンフュージョン

コンテキストコンフュージョンは、無関係な情報が品質を低下させる形でレスポンスに影響を与える時に発生します。これはディストラクションに関連していますが異なります—コンフュージョンは、アテンション配分ではなく、コンテキストがモデルの動作に与える影響に関するものです。

コンテキストに何かを入れると、モデルはそれに注意を払わなければなりません。モデルは無関係な情報を組み込んだり、不適切なツール定義を使用したり、異なるコンテキストからの制約を適用したりする可能性があります。コンフュージョンは、コンテキストに複数のタスクタイプが含まれている場合や、単一のセッション内でタスクを切り替える場合に特に問題になります。

**コンフュージョンの兆候**
クエリの間違った側面に対処するレスポンス、異なるタスクに適切と思われるツールコール、または複数のソースからの要件が混在する出力に注意してください。これらは、現在の状況にどのコンテキストが適用されるかについてのコンフュージョンを示しています。

**アーキテクチャソリューション**
アーキテクチャソリューションには、異なるタスクが異なるコンテキストウィンドウを取得する明示的なタスクセグメンテーション、タスクコンテキスト間の明確なトランジション、および異なる目標のためにコンテキストを分離する状態管理が含まれます。

### コンテキストクラッシュ

コンテキストクラッシュは、蓄積された情報が直接矛盾し、推論を脱線させる矛盾したガイダンスを作成する時に発展します。これは、1つの情報が不正確であるポイズニングとは異なります—クラッシュでは、複数の正しい情報が互いに矛盾します。

**クラッシュの原因**
クラッシュは一般的に、異なるソースが矛盾する情報を持つマルチソース検索、古い情報と最新の情報の両方がコンテキストに表示されるバージョンの競合、および異なる視点が有効だが互換性がないパースペクティブの競合から発生します。

**解決アプローチ**
解決アプローチには、矛盾を特定して明確化を求める明示的な競合マーキング、どのソースが優先されるかを確立する優先ルール、およびコンテキストから古い情報を除外するバージョンフィルタリングが含まれます。

### 実証的ベンチマークと閾値

研究は、設計判断に情報を提供する劣化パターンに関する具体的なデータを提供します。

**RULERベンチマークの調査結果**
RULERベンチマークは厳しい調査結果を提供します：32K以上のコンテキストを主張するモデルの50%のみが32Kトークンで満足のいくパフォーマンスを維持します。GPT-5.2は現在のモデルの中で最も劣化が少なく、多くのモデルは拡張コンテキストで30ポイント以上低下します。単純なneedle-in-haystackテストでのほぼ完璧なスコアは、実際の長いコンテキストの理解には反映されません。

**モデル別劣化閾値**
| モデル | 劣化開始 | 重度の劣化 | 備考 |
|-------|-------------------|-------------------|-------|
| GPT-5.2 | 〜64Kトークン | 〜200Kトークン | thinkingモードで最高の全体的な劣化耐性 |
| Claude Opus 4.5 | 〜100Kトークン | 〜180Kトークン | 200Kコンテキストウィンドウ、強力なアテンション管理 |
| Claude Sonnet 4.5 | 〜80Kトークン | 〜150Kトークン | エージェントとコーディングタスクに最適化 |
| Gemini 3 Pro | 〜500Kトークン | 〜800Kトークン | 1Mコンテキストウィンドウ、ネイティブマルチモダリティ |
| Gemini 3 Flash | 〜300Kトークン | 〜600Kトークン | Gemini 2.5の3倍の速度、81.2% MMMU-Pro |

**モデル別動作パターン**
異なるモデルは、コンテキストのプレッシャー下で異なる障害モードを示します：

- **Claude 4.5シリーズ**: 校正された不確実性で最低のハルシネーション率。Claude Opus 4.5はSWE-bench Verifiedで80.9%を達成。捏造するよりも拒否や明確化の要求を行う傾向。
- **GPT-5.2**: 2つのモードが利用可能 - instant（高速）とthinking（推論）。thinkingモードはステップバイステップの検証によりハルシネーションを減少させますが、レイテンシが増加します。
- **Gemini 3 Pro/Flash**: 1Mコンテキストウィンドウによるネイティブマルチモダリティ。Gemini 3 Flashは前世代の3倍の速度向上を提供。テキスト、コード、画像、音声、動画にわたるマルチモーダル推論に強い。

これらのパターンは、異なるユースケースに対するモデル選択に情報を提供します。高リスクタスクにはClaude 4.5の保守的なアプローチやGPT-5.2のthinkingモードが有益であり、速度重視のタスクにはinstantモードが使用されます。

### 直感に反する調査結果

研究は、コンテキスト管理に関する仮定に挑戦するいくつかの直感に反するパターンを明らかにしています。

**シャッフルされたヘイスタックは一貫性のあるものを上回る**
研究によると、シャッフルされた（非一貫性の）ヘイスタックは論理的に一貫性のあるものよりも良いパフォーマンスを生み出します。これは、一貫性のあるコンテキストが検索を混乱させる偽の関連を作成する可能性がある一方、非一貫性のコンテキストはモデルに正確なマッチングへの依存を強制することを示唆しています。

**単一のディストラクターが過大な影響を持つ**
たった1つの無関係なドキュメントでもパフォーマンスを大幅に低下させます。効果はノイズの量に比例するのではなく、ディストラクターの存在が劣化を引き起こすステップ関数に従います。

**Needle-Questionの類似性相関**
needleとquestionペアの類似性が低いほど、コンテキストの長さに伴う劣化が速くなります。異なるコンテンツ間の推論を必要とするタスクは特に脆弱です。

### より大きなコンテキストが害になる場合

より大きなコンテキストウィンドウは一様にパフォーマンスを向上させるわけではありません。多くの場合、より大きなコンテキストは利点を上回る新しい問題を生み出します。

**パフォーマンス劣化曲線**
モデルはコンテキストの長さに対して非線形な劣化を示します。パフォーマンスは閾値まで安定を保ち、その後急速に劣化します。閾値はモデルとタスクの複雑さによって異なります。多くのモデルでは、コンテキストウィンドウがはるかに大きなサイズをサポートしていても、8,000〜16,000トークン前後で意味のある劣化が始まります。

**コストへの影響**
処理コストはコンテキストの長さに対して不均衡に増大します。400Kトークンのコンテキストを処理するコストは200Kの2倍ではなく—時間と計算リソースの両方で指数関数的に増加します。多くのアプリケーションにとって、これにより大規模コンテキスト処理は経済的に非現実的になります。

**認知負荷のメタファー**
無限のコンテキストがあっても、単一のモデルに数十の独立したタスクにわたって一貫した品質を維持するよう求めることは、認知的なボトルネックを作成します。モデルは常にアイテム間でコンテキストを切り替え、比較フレームワークを維持し、スタイルの一貫性を確保する必要があります。これはより多くのコンテキストが解決する問題ではありません。

## 実践ガイダンス

### 4バケットアプローチ

4つの戦略がコンテキスト劣化の異なる側面に対処します：

**書き出す（Write）**: スクラッチパッド、ファイルシステム、または外部ストレージを使用してコンテキストをウィンドウの外に保存します。これにより、情報アクセスを維持しながらアクティブなコンテキストをスリムに保ちます。

**選択する（Select）**: 検索、フィルタリング、および優先順位付けを通じて、関連するコンテキストをウィンドウに取り込みます。これにより、無関係な情報を除外してディストラクションに対処します。

**圧縮する（Compress）**: 要約、抽象化、および観察マスキングを通じて、情報を保持しながらトークンを削減します。これにより、効果的なコンテキスト容量が拡張されます。

**分離する（Isolate）**: コンテキストをサブエージェントまたはセッションに分割して、単一のコンテキストが劣化するほど大きくなるのを防ぎます。これは最も積極的な戦略ですが、多くの場合最も効果的です。

### アーキテクチャパターン

特定のアーキテクチャパターンを通じてこれらの戦略を実装します。ジャストインタイムコンテキストロードを使用して、必要な時にのみ情報を取得します。観察マスキングを使用して、冗長なツール出力をコンパクトな参照に置き換えます。サブエージェントアーキテクチャを使用して、異なるタスクのコンテキストを分離します。コンパクションを使用して、成長するコンテキストが制限を超える前に要約します。

## 例

**例1：劣化の検出**
```yaml
# Context grows during long conversation
turn_1: 1000 tokens
turn_5: 8000 tokens
turn_10: 25000 tokens
turn_20: 60000 tokens (degradation begins)
turn_30: 90000 tokens (significant degradation)
```

**例2：Lost-in-Middleの緩和**
```markdown
# Organize context with critical info at edges

[CURRENT TASK]                      # At start
- Goal: Generate quarterly report
- Deadline: End of week

[DETAILED CONTEXT]                  # Middle (less attention)
- 50 pages of data
- Multiple analysis sections
- Supporting evidence

[KEY FINDINGS]                     # At end
- Revenue up 15%
- Costs down 8%
- Growth in Region A
```

## ガイドライン

1. 開発中にコンテキストの長さとパフォーマンスの相関を監視する
2. 重要な情報をコンテキストの先頭または末尾に配置する
3. 劣化が深刻になる前にコンパクショントリガーを実装する
4. コンテキストに追加する前に検索されたドキュメントの正確性を検証する
5. バージョニングを使用して古い情報がクラッシュを引き起こすのを防ぐ
6. 異なる目標間のコンテキストコンフュージョンを防ぐためにタスクをセグメント化する
7. 完璧な条件を仮定するのではなく、グレースフルデグラデーションを設計する
8. 劣化の閾値を見つけるために、段階的に大きなコンテキストでテストする

## 統合

このスキルはcontext-fundamentalsの上に構築されており、基本的なコンテキストの概念を理解した後に学習すべきです。以下に接続します：

- context-optimization - 劣化を緩和する技術
- multi-agent-patterns - 分離を使用して劣化を防止する
- evaluation - プロダクションでの劣化の測定と検出

## 参考文献

内部参考：
- [Degradation Patterns Reference](./references/patterns.md) - 詳細な技術リファレンス

このコレクションの関連スキル：
- context-fundamentals - コンテキストの基礎
- context-optimization - 緩和技術
- evaluation - 検出と測定

外部リソース：
- アテンションメカニズムとコンテキストウィンドウの制限に関する研究
- 「lost-in-middle」現象に関する研究
- AIラボからのプロダクションエンジニアリングガイド

---

## スキルメタデータ

**作成日**: 2025-12-20
**最終更新日**: 2025-12-20
**著者**: Agent Skills for Context Engineering Contributors
**バージョン**: 1.0.0
