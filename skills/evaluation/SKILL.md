---
name: evaluation
description: このスキルは、ユーザーが「エージェントのパフォーマンスを評価する」「テストフレームワークを構築する」「エージェントの品質を測定する」「評価ルーブリックを作成する」と依頼した場合、またはLLM-as-judge、多次元評価、エージェントテスト、エージェントパイプラインの品質ゲートに言及した場合に使用してください。
---

# エージェントシステムの評価手法

エージェントシステムの評価には、従来のソフトウェアや標準的な言語モデルアプリケーションとは異なるアプローチが必要です。エージェントは動的な意思決定を行い、実行ごとに非決定的であり、単一の正解がないことが多いです。効果的な評価は、これらの特性を考慮しながら、実用的なフィードバックを提供する必要があります。堅牢な評価フレームワークは、継続的な改善を可能にし、リグレッションを検出し、コンテキストエンジニアリングの選択が意図した効果を達成しているかを検証します。

## アクティベーション条件

以下の場合にこのスキルをアクティベートしてください：
- エージェントのパフォーマンスを体系的にテストする場合
- コンテキストエンジニアリングの選択を検証する場合
- 時間経過に伴う改善を測定する場合
- デプロイ前にリグレッションを検出する場合
- エージェントパイプラインの品質ゲートを構築する場合
- 異なるエージェント設定を比較する場合
- 本番システムを継続的に評価する場合

## コアコンセプト

エージェント評価には、非決定性と複数の有効なパスを考慮した、成果に焦点を当てたアプローチが必要です。多次元ルーブリックは、事実の正確性、完全性、引用の正確性、ソースの品質、ツールの効率性など、さまざまな品質側面を捉えます。LLM-as-judgeはスケーラブルな評価を提供し、人間による評価はエッジケースを捕捉します。

重要な洞察は、エージェントは目標への代替パスを見つける可能性があるということです。評価は、合理的なプロセスに従いながら正しい成果を達成しているかどうかを判断すべきです。

**パフォーマンスドライバー：95%の発見**
BrowseComp評価（ブラウジングエージェントが見つけにくい情報を特定する能力をテストする評価）に関する研究では、3つの要因がパフォーマンスの分散の95%を説明することが判明しました：

| 要因 | 説明される分散 | 示唆 |
|------|--------------|------|
| トークン使用量 | 80% | より多くのトークン = より良いパフォーマンス |
| ツール呼び出し回数 | 約10% | より多くの探索が有効 |
| モデルの選択 | 約5% | より良いモデルが効率を倍増 |

この発見は評価設計に重要な示唆を持ちます：
- **トークン予算が重要**：無制限のリソースではなく、現実的なトークン予算でエージェントを評価する
- **モデルのアップグレードはトークン増加に勝る**：Claude Sonnet 4.5やGPT-5.2へのアップグレードは、以前のバージョンでトークン予算を倍増するよりも大きな効果をもたらす
- **マルチエージェント検証**：この発見は、別々のコンテキストウィンドウを持つエージェント間で作業を分散するアーキテクチャを支持する

## 詳細トピック

### 評価の課題

**非決定性と複数の有効なパス**
エージェントは、目標に到達するためにまったく異なる有効なパスをたどる可能性があります。あるエージェントは3つのソースを検索し、別のエージェントは10個を検索するかもしれません。同じ答えを見つけるために異なるツールを使用するかもしれません。特定のステップをチェックする従来の評価は、このコンテキストでは失敗します。

解決策は、合理的なプロセスに従いながらエージェントが正しい成果を達成しているかどうかを判断する、成果に焦点を当てた評価です。

**コンテキスト依存の失敗**
エージェントの失敗は、しばしば微妙な方法でコンテキストに依存します。エージェントは単純なクエリでは成功するが、複雑なクエリでは失敗するかもしれません。あるツールセットではうまく機能するが、別のツールセットでは失敗するかもしれません。コンテキストが蓄積される長時間のインタラクション後にのみ失敗が現れることもあります。

評価は、孤立したクエリだけでなく、さまざまな複雑さのレベルをカバーし、拡張されたインタラクションをテストする必要があります。

**複合品質次元**
エージェントの品質は単一の次元ではありません。事実の正確性、完全性、一貫性、ツールの効率性、プロセスの品質が含まれます。エージェントは正確性では高いスコアを出しながら効率性では低いスコアになる場合があり、その逆もあり得ます。

評価ルーブリックは、ユースケースに適した重み付けで複数の次元を捕捉する必要があります。

### 評価ルーブリックの設計

**多次元ルーブリック**
効果的なルーブリックは、説明的なレベルで主要な次元をカバーします：

事実の正確性：主張がグラウンドトゥルースと一致する（優秀から失敗まで）

完全性：出力が要求された側面をカバーする（優秀から失敗まで）

引用の正確性：引用が主張されたソースと一致する（優秀から失敗まで）

ソースの品質：適切な一次ソースを使用する（優秀から失敗まで）

ツールの効率性：適切なツールを適切な回数使用する（優秀から失敗まで）

**ルーブリックのスコアリング**
次元の評価を数値スコア（0.0〜1.0）に変換し、適切な重み付けを行います。加重全体スコアを計算します。ユースケースの要件に基づいて合格閾値を決定します。

### 評価手法

**LLM-as-Judge**
LLMベースの評価は、大規模なテストセットにスケールし、一貫した判断を提供します。重要なのは、関心のある次元を捉える効果的な評価プロンプトを設計することです。

明確なタスクの説明、エージェントの出力、グラウンドトゥルース（利用可能な場合）、レベルの説明付き評価スケール、構造化された判断の要求を提供します。

**人間による評価**
人間による評価は、自動化では見逃すものを捕捉します。人間は、珍しいクエリに対するハルシネーションされた回答、システム障害、自動評価では見逃す微妙なバイアスに気付きます。

効果的な人間による評価は、エッジケースをカバーし、体系的にサンプリングし、パターンを追跡し、文脈的な理解を提供します。

**最終状態評価**
永続的な状態を変更するエージェントについては、最終状態評価は、エージェントがどのようにそこに到達したかではなく、最終状態が期待と一致しているかどうかに焦点を当てます。

### テストセットの設計

**サンプル選択**
開発中は小さなサンプルから始めます。エージェント開発の初期段階では、容易に改善できる点が豊富にあるため、変更が劇的な影響を与えます。小さなテストセットで大きな効果が明らかになります。

実際の使用パターンからサンプルを取ります。既知のエッジケースを追加します。複雑さのレベル全体でカバレッジを確保します。

**複雑さの層別化**
テストセットは、複雑さのレベルを網羅する必要があります：単純（単一ツール呼び出し）、中程度（複数ツール呼び出し）、複雑（多数のツール呼び出し、大きな曖昧さ）、非常に複雑（拡張されたインタラクション、深い推論）。

### コンテキストエンジニアリングの評価

**コンテキスト戦略のテスト**
コンテキストエンジニアリングの選択は、体系的な評価を通じて検証すべきです。同じテストセットで異なるコンテキスト戦略を持つエージェントを実行します。品質スコア、トークン使用量、効率性メトリクスを比較します。

**劣化テスト**
異なるコンテキストサイズでエージェントを実行することで、コンテキストの劣化がパフォーマンスにどのように影響するかをテストします。コンテキストが問題になるパフォーマンスの急落を特定します。安全な動作範囲を確立します。

### 継続的評価

**評価パイプライン**
エージェントの変更時に自動的に実行される評価パイプラインを構築します。結果を時系列で追跡します。バージョンを比較して改善やリグレッションを特定します。

**本番監視**
インタラクションをサンプリングしランダムに評価することで、本番環境で評価メトリクスを追跡します。品質低下のアラートを設定します。トレンド分析のためのダッシュボードを維持します。

## 実践ガイダンス

### 評価フレームワークの構築

1. ユースケースに関連する品質次元を定義する
2. 明確で実用的なレベルの説明を持つルーブリックを作成する
3. 実際の使用パターンとエッジケースからテストセットを構築する
4. 自動評価パイプラインを実装する
5. 変更を加える前にベースラインメトリクスを確立する
6. すべての重要な変更に対して評価を実行する
7. トレンド分析のために時系列でメトリクスを追跡する
8. 自動評価を人間によるレビューで補完する

### 評価の落とし穴の回避

特定のパスへの過剰適合：特定のステップではなく、成果を評価する。
エッジケースの無視：多様なテストシナリオを含める。
単一メトリクスへの執着：多次元ルーブリックを使用する。
コンテキスト効果の軽視：現実的なコンテキストサイズでテストする。
人間による評価の省略：自動評価は微妙な問題を見逃す。

## 例

**例1：シンプルな評価**
```python
def evaluate_agent_response(response, expected):
    rubric = load_rubric()
    scores = {}
    for dimension, config in rubric.items():
        scores[dimension] = assess_dimension(response, expected, dimension)
    overall = weighted_average(scores, config["weights"])
    return {"passed": overall >= 0.7, "scores": scores}
```

**例2：テストセットの構造**

テストセットは、包括的な評価を確保するために複数の複雑さのレベルを網羅する必要があります：

```python
test_set = [
    {
        "name": "simple_lookup",
        "input": "What is the capital of France?",
        "expected": {"type": "fact", "answer": "Paris"},
        "complexity": "simple",
        "description": "Single tool call, factual lookup"
    },
    {
        "name": "medium_query",
        "input": "Compare the revenue of Apple and Microsoft last quarter",
        "complexity": "medium",
        "description": "Multiple tool calls, comparison logic"
    },
    {
        "name": "multi_step_reasoning",
        "input": "Analyze sales data from Q1-Q4 and create a summary report with trends",
        "complexity": "complex",
        "description": "Many tool calls, aggregation, analysis"
    },
    {
        "name": "research_synthesis",
        "input": "Research emerging AI technologies, evaluate their potential impact, and recommend adoption strategy",
        "complexity": "very_complex",
        "description": "Extended interaction, deep reasoning, synthesis"
    }
]
```

## ガイドライン

1. 単一メトリクスではなく、多次元ルーブリックを使用する
2. 特定の実行パスではなく、成果を評価する
3. 単純から複雑までの複雑さのレベルをカバーする
4. 現実的なコンテキストサイズと履歴でテストする
5. リリース前だけでなく、継続的に評価を実行する
6. LLM評価を人間によるレビューで補完する
7. トレンド検出のために時系列でメトリクスを追跡する
8. ユースケースに基づいて明確な合格/不合格の閾値を設定する

## 統合

このスキルは、横断的な関心事としてすべての他のスキルと接続します：

- context-fundamentals - コンテキスト使用の評価
- context-degradation - 劣化の検出
- context-optimization - 最適化の有効性の測定
- multi-agent-patterns - 連携の評価
- tool-design - ツールの有効性の評価
- memory-systems - メモリ品質の評価

## 参考資料

内部参考資料：
- [Metrics Reference](./references/metrics.md) - 詳細な評価メトリクスと実装

## 参考資料

内部スキル：
- すべての他のスキルが品質測定のために評価と接続する

外部リソース：
- LLM評価ベンチマーク
- エージェント評価に関する研究論文
- 本番監視のプラクティス

---

## スキルメタデータ

**作成日**: 2025-12-20
**最終更新日**: 2025-12-20
**著者**: Agent Skills for Context Engineering Contributors
**バージョン**: 1.0.0
